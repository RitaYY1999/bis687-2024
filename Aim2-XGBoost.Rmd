---
title: "Aim2 XGBoost"
author: "Yuchen Chang"
date: "2024-04-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readxl) 
#setwd("/Users/gladyswang/Desktop/Spring_2024/DS_Capstone")
sickle_cell <- read.csv("/Users/yuchen/Desktop/687/cell/CSV/curesc_year3_v3.csv")
```

# Data Preprocessing
```{r}
# filter out variables with same value
print_columns_same_value <- function(df) {
  same_value_columns <- sapply(df, function(col) length(unique(col)) == 1)
  names(df)[same_value_columns]
}
variables_with_same_value <- print_columns_same_value(sickle_cell)
sickle_cell <- sickle_cell[, !names(sickle_cell) %in% variables_with_same_value]
```


```{r}
# extract pre-HCT variables
codebook <- read_excel("/Users/yuchen/Desktop/687/cell/CSV/Codebook 2021 Year 3.xlsx")
codebook_prehct <- codebook[codebook['HCT status'] == "pre-HCT",]
completeRows <- complete.cases(codebook_prehct["HCT status"])
codebook_prehct <- codebook_prehct[completeRows, ]
codebook_prehct[codebook_prehct$`Variable name` == "racegp", 'Variable name'] <- 'raceg'
names(sickle_cell) <- tolower(names(sickle_cell))
common_columns <- intersect(names(sickle_cell), codebook_prehct$`Variable name`)
sickle_cell_prehct <- sickle_cell[, common_columns]
names(sickle_cell_prehct) <- toupper(names(sickle_cell_prehct))
sickle_cell_prehct$ACSPSHI <- sickle_cell$acspshi
```

```{r}
# remove duplicate variables
duplicate_variables <- c("AGE", "YEARTX", "SCREUNIT", "SCRENUNT", "SALBUNIT", "SALBNUNT", "HB1UNPR")
sickle_cell_prehct <- sickle_cell_prehct[, !names(sickle_cell_prehct) %in% duplicate_variables]
```

```{r}
# remove variables with >= 60% missing values
missing_percentage <- function(df, missing_values = c(NA, 99, -9)) {
  total_values <- sapply(df, function(col) length(col))
  missing_count <- sapply(df, function(col) sum(col %in% missing_values))
  missing_percentage <- round((missing_count / total_values) * 100, 2)
  return(missing_percentage)
}

missing_percentages <- missing_percentage(sickle_cell_prehct)
variables_to_remove <- names(missing_percentages)[missing_percentages >= 60]
sickle_cell_cleaned <- sickle_cell_prehct[, !names(sickle_cell_prehct) %in% variables_to_remove]
```

```{r}
# remove samples with unrecorded ACSPSHI
sickle_cell_cleaned <- sickle_cell_cleaned[sickle_cell_cleaned$ACSPSHI != 99, ]
```

```{r}
library(missForest)

# Perform imputation (this might take some time for larger datasets)
col_names<-c("SCREATPR", "SCREAULN", "HB1PR", "INTSCREPR", "AGEGPFF")
sickle_cell_cleaned[setdiff(names(sickle_cell_cleaned), col_names)] <- lapply(sickle_cell_cleaned[setdiff(names(sickle_cell_cleaned), col_names)], factor)

imputed_data <- missForest(sickle_cell_cleaned)$ximp

sickle_cell_imputed <- imputed_data
```

```{r}
library(caret)
library(xgboost)
```

```{r}
# Get dataset
imputed_data <- imputed_data[, c("HCTCIGPF", "GVHD_FINAL", "CONDGRP_FINAL", "CONDGRPF", "SCATXRSN", 
                             "HB1PR", "SCREAULN", "SCREATPR", "YEARGPF", "DONORF", "ETHNICIT", 
                             "INTSCREPR", "HLA_FINAL", "VOC2YPR", "SNEPHRPR", "ACSPSHI")]
# One-hot Encoding variables
col_names<-c("SCREATPR", "SCREAULN", "HB1PR", "INTSCREPR")
X <- imputed_data[,1:14]
columns_to_encode <- setdiff(names(X), col_names)
data_encoded <- dummyVars("~.", data = X[, columns_to_encode], fullRank = TRUE) %>%
  predict(newdata = X[, columns_to_encode])

# Combine encoded columns with the numeric columns
data_combined <- cbind(X[, col_names], data_encoded)
```

```{r}
# Start to build Model
set.seed(12315)
Y <- as.numeric(as.character(imputed_data$ACSPSHI))
X <- data_combined
n <- nrow(imputed_data)
train_indices <- sample(1:n, 0.75 * n)  # 75% for training
val_indices <- setdiff(1:n, train_indices)  # Remaining 20% for validation
X_train <- data_combined[train_indices, ]
Y_train <- Y[train_indices]
X_val <- data_combined[val_indices, ]
Y_val <- Y[val_indices]

# Create xgb.DMatrix
dtrain <-xgb.DMatrix(as.matrix(sapply(X_train, as.numeric)),label=Y_train)
dtest <- xgb.DMatrix(as.matrix(sapply(X_val, as.numeric)),label=Y_val)

# Train an XGBoost model
xgb_model <- xgboost(data = dtrain,
                     nrounds = 100, 
                     objective = "binary:logistic",
                     eta = 0.3, 
                     max_depth = 6)  

# Make predictions on the prediction data
pred <- predict(xgb_model, as.matrix(X_val))
predicted_labels <- ifelse(pred > 0.5, 1, 0) 
```

```{r}
# Calculate AUC and ROC curve
roc <- roc(as.numeric(Y_val), as.numeric(pred))
auc <- auc(roc)
plot(roc, main = "ROC Curve", col = "blue", lwd = 2)
```

```{r}
# Sensitivity Analysis
conf_matrix <- confusionMatrix(factor(predicted_labels), factor(Y_val))
print(conf_matrix)
```

```{r}
# Perform grid search
# Set up cross-validation
control <- trainControl(method = "cv", number = 5)

xgb_grid <- expand.grid(
  nrounds = c(100, 200, 300),  # Example values for number of boosting rounds
  max_depth = c(3, 6, 9),       # Example values for maximum tree depth
  eta = c(0.01, 0.1, 0.3),      # Example values for learning rate
  gamma = c(0, 0.1),       
  colsample_bytree = c(0.6, 0.8),  
  min_child_weight = c(1, 3),      
  subsample = c(0.6, 0.8)          
)
# Get best model
best_model <- xgb_tune$finalModel

# Print best model parameters
print(best_model)
```
